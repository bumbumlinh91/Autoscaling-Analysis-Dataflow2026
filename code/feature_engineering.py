"""
MODULE: Feature Engineering Pipeline
-------------------------------------------------------------------
M√¥ t·∫£:
    Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu chu·ªói th·ªùi gian th√¥ th√†nh 
    Feature Matrix ƒë·ªÉ ph·ª•c v·ª• hu·∫•n luy·ªán m√¥ h√¨nh h·ªçc m√°y.

C√°c k·ªπ thu·∫≠t √°p d·ª•ng:
    1. Time Continuity Restoration: T√°i t·∫°o tr·ª•c th·ªùi gian li√™n t·ª•c ƒë·ªÉ x·ª≠ l√Ω c√°c kho·∫£ng tr·ªëng 
       do qu√° tr√¨nh l·ªçc nhi·ªÖu g√¢y ra.
    2. Cyclical Encoding: M√£ h√≥a l∆∞·ª£ng gi√°c (Sin/Cos) cho ƒë·∫∑c tr∆∞ng th·ªùi gian (Gi·ªù, Th·ª©).
    3. Rolling Statistics: T√≠nh to√°n xu h∆∞·ªõng tr∆∞·ª£t ƒë·ªÉ b·∫Øt t√≠n hi·ªáu Trend/Volatility.
    4. Dynamic Lagging: T·ª± ƒë·ªông t√≠nh to√°n b∆∞·ªõc tr·ªÖ d·ª±a tr√™n t·∫ßn su·∫•t d·ªØ li·ªáu .

"""

import yaml
import logging
import pandas as pd
import numpy as np
from pathlib import Path
import re
import warnings
import sys

# T·∫Øt c·∫£nh b√°o FutureWarnings
warnings.filterwarnings('ignore')

# C·∫§U H√åNH LOGGING & CONFIG

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

def load_config():
    """
    T·∫£i c·∫•u h√¨nh h·ªá th·ªëng t·ª´ file YAML v·ªõi c∆° ch·∫ø t·ª± ƒë·ªông d√≤ t√¨m ƒë∆∞·ªùng d·∫´n.
    ƒê·∫£m b·∫£o t√≠nh linh ho·∫°t khi ch·∫°y script t·ª´ c√°c th∆∞ m·ª•c kh√°c nhau.
    """
    search_paths = [
        Path("config/config.yaml"), 
        Path("../config/config.yaml"), 
        Path("../../config/config.yaml")
    ]
    for p in search_paths:
        if p.exists():
            with open(p, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
    
    logger.error("‚ùå CRITICAL: Kh√¥ng t√¨m th·∫•y t·ªáp c·∫•u h√¨nh 'config.yaml'.")
    sys.exit(1)

CONFIG = load_config()

# CLASS X·ª¨ L√ù TRUNG T√ÇM
class FeatureEngineeringPipeline:
    def __init__(self, config):
        self.config = config
        
    def _parse_interval_minutes(self, interval_str):
        """
        Ph√¢n t√≠ch chu·ªói ƒë·ªãnh d·∫°ng '5min', '15min' sang s·ªë nguy√™n ph√∫t.
        H·ªó tr·ª£ t√≠nh to√°n s·ªë b∆∞·ªõc nh·∫£y cho Lag Features.
        """
        match = re.match(r"(\d+)", interval_str)
        return int(match.group(1)) if match else 5

    def _restore_time_continuity(self, df, interval_str):
        """
        Kh√¥i ph·ª•c t√≠nh li√™n t·ª•c c·ªßa th·ªùi gian (Time Index Reconstruction).
        
        V·∫•n ƒë·ªÅ: D·ªØ li·ªáu sau EDA b·ªã c·∫Øt b·ªè m·ªôt kho·∫£ng b√£o/l·ªói. N·∫øu d√πng shift() tr·ª±c ti·∫øp,
        Model s·∫Ω h·ªçc sai quy lu·∫≠t (nh√¨n nh·∫ßm d·ªØ li·ªáu c·ªßa 5 ng√†y tr∆∞·ªõc th√†nh d·ªØ li·ªáu v·ª´a x·∫£y ra).
        
        Gi·∫£i ph√°p: 
        1. T·∫°o m·ªôt tr·ª•c th·ªùi gian chu·∫©n ƒë·∫ßy ƒë·ªß .
        2. Reindex DataFrame v√†o tr·ª•c n√†y. C√°c kho·∫£ng tr·ªëng s·∫Ω ƒë∆∞·ª£c l·∫•p ƒë·∫ßy b·∫±ng NaN.
        3. Khi t√≠nh to√°n Lag, shift() s·∫Ω g·∫∑p NaN -> Lag ch√≠nh x√°c v·ªÅ m·∫∑t v·∫≠t l√Ω.
        """
        if 'ds' not in df.columns:
            raise ValueError("DataFrame thi·∫øu c·ªôt 'ds' (Timestamp).")

        df = df.set_index('ds').sort_index()
        
        # X√°c ƒë·ªãnh t·∫ßn su·∫•t chu·∫©n
        minutes = self._parse_interval_minutes(interval_str)
        freq = f"{minutes}T" # V√≠ d·ª•: '1T', '5T', '15T'
        
        # T·∫°o tr·ª•c th·ªùi gian li√™n t·ª•c t·ª´ ƒëi·ªÉm ƒë·∫ßu ƒë·∫øn ƒëi·ªÉm cu·ªëi
        full_idx = pd.date_range(start=df.index.min(), end=df.index.max(), freq=freq)
        
        # Reindex: C√°c ƒëi·ªÉm b·ªã thi·∫øu s·∫Ω sinh ra d√≤ng m·ªõi v·ªõi gi√° tr·ªã NaN
        df_restored = df.reindex(full_idx)
        
        logger.debug(f"   üîß ƒê√£ kh√¥i ph·ª•c tr·ª•c th·ªùi gian: {len(df)} -> {len(df_restored)} d√≤ng (Th√™m {len(df_restored)-len(df)} kho·∫£ng tr·ªëng).")
        
        # Reset index ƒë·ªÉ tr·∫£ l·∫°i c·ªôt 'ds'
        return df_restored.reset_index().rename(columns={'index': 'ds'})

    def generate_cyclical_features(self, df):
        """
        M√£ h√≥a ƒë·∫∑c tr∆∞ng chu k·ª≥ cho th·ªùi gian.
        
        L√Ω do: M√°y h·ªçc kh√¥ng hi·ªÉu t√≠nh tu·∫ßn ho√†n c·ªßa gi·ªù gi·∫•c (23h v√† 0h r·∫•t xa nhau v·ªÅ s·ªë h·ªçc).
        Ph√©p bi·∫øn ƒë·ªïi Sin/Cos ƒë∆∞a ch√∫ng v·ªÅ g·∫ßn nhau tr√™n kh√¥ng gian vector.
        """
        df = df.copy()
        
        # Tr√≠ch xu·∫•t th√¥ng tin th·ªùi gian
        df['hour'] = df['ds'].dt.hour
        df['day_of_week'] = df['ds'].dt.dayofweek
        
        # 1. Chu k·ª≥ Ng√†y (24h)
        # Gi√∫p model hi·ªÉu t·∫£i tr·ªçng ƒë·ªânh th∆∞·ªùng r∆°i v√†o tr∆∞a/chi·ªÅu
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        
        # 2. Chu k·ª≥ Tu·∫ßn (7 ng√†y)
        # Gi√∫p model ph√¢n bi·ªát ng√†y th∆∞·ªùng v√† cu·ªëi tu·∫ßn m·ªôt c√°ch m∆∞·ª£t m√†
        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
        
        # 3. ƒê·∫∑c tr∆∞ng Cu·ªëi tu·∫ßn (Boolean) 
        df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)
        
        # Lo·∫°i b·ªè c√°c c·ªôt th√¥ ƒë·ªÉ gi·∫£m nhi·ªÖu 
        # df.drop(columns=['hour', 'day_of_week'], inplace=True)
        
        return df

    def generate_lag_rolling_features(self, df, interval_str):
        """
        T·∫°o ƒë·∫∑c tr∆∞ng chu·ªói th·ªùi gian ƒë·ªông theo khung th·ªùi gian.
        
        T·ª± ƒë·ªông t√≠nh to√°n s·ªë b∆∞·ªõc d·ª±a tr√™n interval:
        - 1min: 1h = 60 steps
        - 5min: 1h = 12 steps
        - 15min: 1h = 4 steps
        """
        df = df.copy()
        target_col = 'intensity'
        
        # T√≠nh to√°n s·ªë b∆∞·ªõc nh·∫£y 
        minutes = self._parse_interval_minutes(interval_str)
        steps_per_hour = 60 // minutes
        steps_per_day = 24 * steps_per_hour
        steps_per_week = 7 * steps_per_day
        
        logger.info(f"    C·∫•u h√¨nh Feature cho {interval_str}: 1h={steps_per_hour} steps, 24h={steps_per_day} steps.")
        
        # A. LAG FEATURES 
        # -----------------------------------------------------------
        lags = {
            'lag_1step': 1,                 # Ngay tr∆∞·ªõc ƒë√≥
            'lag_1h': steps_per_hour,       # 1 gi·ªù tr∆∞·ªõc 
            'lag_24h': steps_per_day,       # C√πng gi·ªù ng√†y h√¥m qua 
            'lag_7d': steps_per_week        # C√πng gi·ªù tu·∫ßn tr∆∞·ªõc
        }
        
        for name, step in lags.items():
            df[name] = df[target_col].shift(step)
            
        # B. ROLLING FEATURES 
        # -----------------------------------------------------------
        # C·ª≠a s·ªï quan s√°t: 4 gi·ªù g·∫ßn nh·∫•t
        window_size = steps_per_hour * 4 
        
        # L∆∞u √Ω QUAN TR·ªåNG: Ph·∫£i Shift(1) tr∆∞·ªõc khi Rolling ƒë·ªÉ tr√°nh Data Leakage 
        shifted = df[target_col].shift(1)
        
        df['roll_mean_4h'] = shifted.rolling(window=window_size).mean() # Xu h∆∞·ªõng trung b√¨nh
        df['roll_std_4h'] = shifted.rolling(window=window_size).std()   # ƒê·ªô bi·∫øn ƒë·ªông 
        df['roll_max_4h'] = shifted.rolling(window=window_size).max()   # ƒê·ªânh t·∫£i c·ª•c b·ªô
        
        return df

    def cleanup_and_validate(self, df, target_col='intensity'):
        """
        Lo·∫°i b·ªè c√°c d√≤ng NaN sinh ra do Lag/Rolling ho·∫∑c do qu√° tr√¨nh Reindex (V√πng Gap).
        """
        initial_len = len(df)
        
        # Ch·ªâ gi·ªØ l·∫°i c√°c d√≤ng c√≥ Target h·ª£p l·ªá 
        # (T·ª± ƒë·ªông lo·∫°i b·ªè c√°c d√≤ng Gap NaN v√† c√°c d√≤ng ƒë·∫ßu ti√™n ch∆∞a ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh Lag)
        df_clean = df.dropna(subset=[target_col, 'lag_24h', 'roll_mean_4h']).copy()
        
        # Fill NaN c√≤n s√≥t l·∫°i (n·∫øu c√≥) b·∫±ng 0 ƒë·ªÉ an to√†n cho Model
        df_clean = df_clean.fillna(0)
        
        dropped = initial_len - len(df_clean)
        logger.info(f"   üßπ ƒê√£ d·ªçn d·∫πp {dropped:,} d√≤ng (NaN do Gap & Warm-up period).")
            
        return df_clean

    def execute(self):
        """
        H√†m ƒëi·ªÅu ph·ªëi ch√≠nh.
        Th·ª±c hi·ªán quy tr√¨nh cho to√†n b·ªô c√°c khung th·ªùi gian ƒë∆∞·ª£c y√™u c·∫ßu.
        """
        base_dir = Path(__file__).resolve().parent.parent
        data_dir = base_dir / "data"
        
        # Dictionary ƒë·ªÉ l∆∞u Context t·ª´ t·∫≠p Train (d√πng ƒë·ªÉ n·ªëi v√†o ƒë·∫ßu t·∫≠p Test)
        train_context_cache = {}
        
        # X·ª≠ l√Ω 3 khung th·ªùi gian
        target_intervals = ['1min', '5min', '15min']

        print("\n" + "="*70)
        print(" üöÄ FEATURE ENGINEERING ENGINE (PRO VERSION)")
        print(f"    Target Intervals: {target_intervals}")
        print("="*70)

        for dataset_type in ['train', 'test']:
            print(f"\nüìÇ ƒêang x·ª≠ l√Ω t·∫≠p d·ªØ li·ªáu: {dataset_type.upper()}")
            
            for interval in target_intervals:
                # File ƒë·∫ßu v√†o t·ª´ b∆∞·ªõc Preprocessing
                input_file = f"processed_{dataset_type}_{interval}.csv"
                # File ƒë·∫ßu ra cho Training
                output_file = f"prepared_{dataset_type}_{interval}.csv"
                
                input_path = data_dir / input_file
                output_path = data_dir / output_file
                
                if not input_path.exists():
                    logger.warning(f"   ‚ö†Ô∏è B·ªè qua {interval}: Kh√¥ng t√¨m th·∫•y file ngu·ªìn {input_file}")
                    # N·∫øu file 1min/15min ch∆∞a c√≥, b·ªè qua lu√¥n
                    continue

                logger.info(f"‚ñ∂ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω: {interval}")

                # 1. Load D·ªØ li·ªáu s·∫°ch
                df = pd.read_csv(input_path)
                df['ds'] = pd.to_datetime(df['ds'])
                
                # --- LOGIC: X·ª¨ L√ù CONTEXT CHO TEST (TR√ÅNH M·∫§T D·ªÆ LI·ªÜU ƒê·∫¶U K·ª≤) ---
                original_test_start = None
                
                if dataset_type == 'test' and interval in train_context_cache:
                    original_test_start = df['ds'].min()
                    # L·∫•y context t·ª´ train n·ªëi v√†o tr∆∞·ªõc test
                    context_df = train_context_cache[interval]
                    df = pd.concat([context_df, df], axis=0, ignore_index=True)
                    # X√≥a tr√πng l·∫∑p n·∫øu c√≥ 
                    df = df.drop_duplicates(subset=['ds']).sort_values('ds')

                # 2. Kh√¥i ph·ª•c t√≠nh li√™n t·ª•c (Ch·∫°y tr√™n d·ªØ li·ªáu ƒë√£ n·ªëi ƒë·ªÉ l·∫•p gap gi·ªØa train-test)
                df = self._restore_time_continuity(df, interval)
                
                # N·∫øu l√† Train, l∆∞u l·∫°i 8 ng√†y cu·ªëi l√†m context cho Test (ƒë·ªß cho lag_7d)
                if dataset_type == 'train':
                    cutoff_time = df['ds'].max() - pd.Timedelta(days=8)
                    train_context_cache[interval] = df[df['ds'] > cutoff_time].copy()
                # --------------------------------------------------------------------

                # 3. T·∫°o ƒë·∫∑c tr∆∞ng th·ªùi gian 
                df = self.generate_cyclical_features(df)
                
                # 4. T·∫°o ƒë·∫∑c tr∆∞ng chu·ªói ƒë·ªông 
                df = self.generate_lag_rolling_features(df, interval)
                
                # --- C·∫ÆT TR·∫¢ V·ªÄ ƒê√öNG K√çCH TH∆Ø·ªöC TEST ---
                if dataset_type == 'test' and original_test_start is not None:
                    df = df[df['ds'] >= original_test_start].copy()
                
                # 5. D·ªçn d·∫πp & Ki·ªÉm tra
                df = self.cleanup_and_validate(df)
                
                # 6. L∆∞u k·∫øt qu·∫£
                df.to_csv(output_path, index=False)
                logger.info(f"   ‚úÖ Ho√†n t·∫•t: {output_file} | Shape: {df.shape}")

# ENTRY POINT
if __name__ == "__main__":
    try:
        pipeline = FeatureEngineeringPipeline(CONFIG)
        pipeline.execute()
        print("\n‚úÖ [SUCCESS] QUY TR√åNH K·ª∏ THU·∫¨T ƒê·∫∂C TR∆ØNG HO√ÄN T·∫§T.")
    except Exception as e:
        logger.error(f"‚ùå [FAILURE] H·ªá th·ªëng g·∫∑p l·ªói: {e}")
        import traceback
        traceback.print_exc()