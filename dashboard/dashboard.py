import streamlit as st
import pandas as pd
import requests
import altair as alt
import numpy as np

def plot_comparison(df, title="So s√°nh Th·ª±c t·∫ø vs D·ª± b√°o"):
    # Bi·ªÉu ƒë·ªì Actual
    base = alt.Chart(df).encode(x=alt.X('ds:T', title='Th·ªùi gian', axis=alt.Axis(format='%H:%M')))
    
    line_actual = base.mark_line(color='gray', strokeDash=[5, 5], opacity=0.7).encode(
        y=alt.Y('y:Q', title='Requests/s'),
        tooltip=[alt.Tooltip('ds:T', format='%H:%M'), alt.Tooltip('y:Q', title='Th·ª±c t·∫ø')]
    )
    # Bi·ªÉu ƒë·ªì Forecast
    line_forecast = base.mark_line(color='#00CC96').encode(
        y=alt.Y('yhat:Q'),
        tooltip=[alt.Tooltip('ds:T', format='%H:%M'), alt.Tooltip('yhat:Q', title='D·ª± b√°o')]
    )
    
    chart = (line_actual + line_forecast).properties(title=title, height=400).interactive()
    return chart

def plot_interactive(df, y_col, color_hex="#FF4B4B", title="Bi·ªÉu ƒë·ªì", y_label="Gi√° tr·ªã"):
    chart = alt.Chart(df).mark_line(color=color_hex).encode(
        x=alt.X('ds:T', title='Th·ªùi gian', axis=alt.Axis(format='%d/%m %H:%M')),
        y=alt.Y(f'{y_col}:Q', title=y_label),
        tooltip=[
            alt.Tooltip('ds:T', title='Th·ªùi gian', format='%Y-%m-%d %H:%M'),
            alt.Tooltip(f'{y_col}:Q', title=y_label, format=',.2f')
        ]
    ).properties(title=title, height=400).interactive()
    return chart
st.set_page_config(page_title="Dataflow 2026 Autoscaling Dashboard", layout="wide")

API_BASE = st.sidebar.text_input("API base URL", "http://127.0.0.1:8000")

# --- LOAD CONFIG T·ª™ API ---
@st.cache_data
def get_default_config(api_url):
    try:
        resp = requests.get(f"{api_url}/config", timeout=5)
        if resp.status_code == 200:
            return resp.json()
    except:
        pass
    return {}

defaults = get_default_config(API_BASE)

st.title("üìà Dataflow 2026 - H·ªá th·ªëng D·ª± b√°o & Autoscaling")

interval = st.sidebar.selectbox("Interval", ["1min", "5min", "15min"], index=2)
model = st.sidebar.selectbox("Model", ["XGBoost", "Prophet", "LSTM"], index=0)

horizon = st.sidebar.number_input(
    "Horizon (s·ªë b∆∞·ªõc d·ª± b√°o)", min_value=1, value=96, step=12,
    help="S·ªë b∆∞·ªõc d·ª± b√°o (>0). V√≠ d·ª•: 1min=60, 5min=288, 15min=96"
)

st.sidebar.markdown("### ‚öôÔ∏è Ch√≠nh s√°ch Scaling")
st.sidebar.caption("Gi√° tr·ªã m·∫∑c ƒë·ªãnh l·∫•y t·ª´ Config")

# L·∫•y default t·ª´ config ho·∫∑c fallback
def_buffer = float(defaults.get("buffer_ratio", 0.2))
def_cooldown = int(defaults.get("cooldown_period", 3))

buffer_ratio = st.sidebar.slider("H·ªá s·ªë d·ª± ph√≤ng", 0.0, 1.0, def_buffer, 0.05)
cooldown_period = st.sidebar.slider("Th·ªùi gian h·∫° nhi·ªát", 0, 20, def_cooldown, 1)

tabs = st.tabs(["üìä 1. D·ª± b√°o & Th·ª±c t·∫ø", "‚öñÔ∏è 2. K·∫ø ho·∫°ch Autoscaling", "üí∞ 3. Ph√¢n t√≠ch chi ph√≠"])

def post_json(path, payload):
    url = f"{API_BASE}{path}"
    # st.caption(f"Calling: {url}")
    try:
        r = requests.post(url, json=payload, timeout=60)
    except requests.exceptions.RequestException as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi API t·∫°i {API_BASE}. H√£y ch·∫Øc ch·∫Øn API ƒëang ch·∫°y.\n\n{e}")
        return None

    if r.status_code != 200:
        st.error(f"L·ªói API {r.status_code}: {r.text}")
        return None
    return r.json()

def forecast_payload():
    return {
        "interval": interval,
        "model": model.lower(),
        "horizon": int(horizon),
        "target": "intensity",  # M·∫∑c ƒë·ªãnh intensity
    }

with tabs[0]:
    st.subheader("AI d·ª± b√°o ch√≠nh x√°c ƒë·∫øn ƒë√¢u?")
    st.markdown("So s√°nh t·∫£i th·ª±c t·∫ø v√† t·∫£i d·ª± b√°o ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô tin c·∫≠y c·ªßa m√¥ h√¨nh.")
    data = post_json("/forecast", forecast_payload())
    if data:
        df = pd.DataFrame(data["points"])
        df["ds"] = pd.to_datetime(df["ds"])
        c1, c2 = st.columns(2)
        c1.metric("S·ªë ƒëi·ªÉm d·ªØ li·ªáu", len(df))
        if "y" in df.columns and df["y"].notna().any():
            mae = np.mean(np.abs(df["y"] - df["yhat"]))
            c2.metric("Sai s·ªë trung b√¨nh (MAE)", f"{mae:.2f}")
            st.altair_chart(plot_comparison(df), use_container_width=True)
        else:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu th·ª±c t·∫ø trong file k·∫øt qu·∫£ ƒë·ªÉ so s√°nh.")
            st.altair_chart(plot_interactive(df, "yhat", "#00CC96", "D·ª± b√°o t·∫£i", "Requests/s"), use_container_width=True)
        
        with st.expander("Xem d·ªØ li·ªáu chi ti·∫øt"):
            st.dataframe(
                df.rename(columns={"ds": "Th·ªùi gian", "y": "Th·ª±c t·∫ø", "yhat": "D·ª± b√°o"}), 
                use_container_width=True
            )

with tabs[1]:
    st.subheader("H·ªá th·ªëng ph·∫£n ·ª©ng th·∫ø n√†o?")
    st.markdown("D·ª±a tr√™n d·ª± b√°o, h·ªá th·ªëng ƒë·ªÅ xu·∫•t s·ªë l∆∞·ª£ng Server c·∫ßn thi·∫øt ƒë·ªÉ ƒë·∫£m b·∫£o SLA.")
    payload = {
        "interval": interval,
        "model": model.lower(),
        "horizon": int(horizon),
        "target": "intensity",
        "policy_params": {
            "buffer_ratio": float(buffer_ratio),
            "cooldown_period": int(cooldown_period),
        }
    }

    data = post_json("/recommend-scaling", payload)
    if data:
        df = pd.DataFrame(data["points"])
        df["ds"] = pd.to_datetime(df["ds"])


        c1, c2 = st.columns([2, 1])
        with c1:
            # V·∫Ω bi·ªÉu ƒë·ªì Replicas vs Load
            base = alt.Chart(df).encode(x=alt.X('ds:T', title='Th·ªùi gian', axis=alt.Axis(format='%H:%M')))
            line_load = base.mark_line(color='#00CC96').encode(y=alt.Y('yhat:Q', title='T·∫£i d·ª± b√°o'), tooltip=['ds', 'yhat'])
            line_rep = base.mark_line(interpolate='step-after', color='#FF4B4B').encode(y=alt.Y('recommended_replicas:Q', title='S·ªë Replicas'), tooltip=['ds', 'recommended_replicas'])
            
            st.altair_chart((line_load + line_rep).resolve_scale(y='independent').properties(title="T·∫£i d·ª± b√°o vs S·ªë Replicas ƒë·ªÅ xu·∫•t"), use_container_width=True)
            
        with c2:
            st.write("üìã **Nh·∫≠t k√Ω h√†nh ƒë·ªông**")
            st.dataframe(
                df[["ds", "recommended_replicas", "action", "reason"]].rename(columns={
                    "ds": "Th·ªùi gian",
                    "recommended_replicas": "Replicas ƒë·ªÅ xu·∫•t",
                    "action": "H√†nh ƒë·ªông",
                    "reason": "L√Ω do"
                }),
                use_container_width=True
            )

with tabs[2]:
    st.subheader("Ph√¢n t√≠ch chi ph√≠ v√† l·ª£i √≠ch")
    st.markdown("So s√°nh chi ph√≠ gi·ªØa vi·ªác d√πng **AI Autoscaling** v√† **Reactive Scaling**.")
    
    # L·∫•y default cost t·ª´ config
    def_cost = float(defaults.get("server_cost", 0.05))      
    def_cap = float(defaults.get("server_capacity", 5000000)) 
    def_penalty = float(defaults.get("sla_penalty", 0.0001)) 

    # Input gi·∫£ ƒë·ªãnh chi ph√≠
    c_cost1, c_cost2, c_cost3 = st.columns(3)
    with c_cost1:
        server_cost = st.number_input("Chi ph√≠ Server ($/gi·ªù/replica)", value=def_cost, step=0.1)
    with c_cost2:
        server_capacity = st.number_input("S·ª©c ch·ªãu t·∫£i (Req/replica)", value=def_cap, step=10000.0)
    with c_cost3:
        sla_penalty = st.number_input("Ph·∫°t SLA ($/req r·ªõt)", value=def_penalty, step=0.0001, format="%.4f")

    # L·∫•y d·ªØ li·ªáu t·ª´ API
    payload = {
        "interval": interval,
        "model": model.lower(),
        "horizon": int(horizon),
        "target": "intensity",
        "policy_params": {
            "buffer_ratio": float(buffer_ratio),
            "cooldown_period": int(cooldown_period),
        }
    }
    data = post_json("/recommend-scaling", payload)
    
    if data:
        df = pd.DataFrame(data["points"])
        df["ds"] = pd.to_datetime(df["ds"])
        
        # --- B∆Ø·ªöC 1: CHU·∫®N B·ªä D·ªÆ LI·ªÜU ---
        if "y" not in df.columns or df["y"].isna().all():
            st.error("‚ö†Ô∏è D·ªØ li·ªáu th·ª±c t·∫ø (y) b·ªã thi·∫øu trong API response! Vui l√≤ng ch·∫°y l·∫°i 'evaluate.py' ƒë·ªÉ c·∫≠p nh·∫≠t k·∫øt qu·∫£.")
            df["y"] = 0
            
        df["y"] = df["y"].fillna(0) # ƒê·∫£m b·∫£o kh√¥ng c√≤n NaN

        # --- B∆Ø·ªöC 2: M√î PH·ªéNG REACTIVE  ---
        # Reactive b·ªã tr·ªÖ 1 nh·ªãp (Lag) so v·ªõi th·ª±c t·∫ø
        # Shift(1) l·∫•y gi√° tr·ªã c·ªßa interval tr∆∞·ªõc ƒë√≥
        lagged_load = df["y"].shift(1).fillna(df["yhat"])
        
        # Buffer 20% 
        df["reactive_replicas"] = np.ceil((lagged_load / server_capacity) * 1.2).astype(int)
        df["reactive_replicas"] = df["reactive_replicas"].clip(lower=1) 
        
        # --- B∆Ø·ªöC 3: T√çNH TO√ÅN CHI PH√ç ---
        hours_per_point = 15 / 60 
        if "1min" in interval: hours_per_point = 1/60
        elif "5min" in interval: hours_per_point = 5/60
            
        # 1. Chi ph√≠ H·∫° t·∫ßng
        df["infra_ai"] = df["recommended_replicas"] * server_cost * hours_per_point
        df["infra_reactive"] = df["reactive_replicas"] * server_cost * hours_per_point
        
        # 2. Chi ph√≠ Ph·∫°t SLA
        # Capacity th·ª±c t·∫ø
        cap_ai = df["recommended_replicas"] * server_capacity
        cap_reactive = df["reactive_replicas"] * server_capacity
        
        # Request b·ªã r·ªõt (Ch·ªâ t√≠nh khi Nhu c·∫ßu > Kh·∫£ nƒÉng)
        df["dropped_ai"] = (df["y"] - cap_ai).clip(lower=0)
        df["dropped_reactive"] = (df["y"] - cap_reactive).clip(lower=0)
        
        df["penalty_ai"] = df["dropped_ai"] * sla_penalty
        df["penalty_reactive"] = df["dropped_reactive"] * sla_penalty
            
        # 3. T·ªïng k·∫øt
        df["total_ai"] = df["infra_ai"] + df["penalty_ai"]
        df["total_reactive"] = df["infra_reactive"] + df["penalty_reactive"]
        
        total_ai = df["total_ai"].sum()
        total_reactive = df["total_reactive"].sum()
        savings = total_reactive - total_ai
        roi = (savings / total_reactive * 100) if total_reactive > 0 else 0
        # --- SLA: % request ph·ª•c v·ª• th√†nh c√¥ng ---
        total_requests = df["y"].sum()

        sla_ai = 1 - (df["dropped_ai"].sum() / total_requests) if total_requests > 0 else 1
        sla_reactive = 1 - (df["dropped_reactive"].sum() / total_requests) if total_requests > 0 else 1

        sla_ai_pct = sla_ai * 100
        sla_reactive_pct = sla_reactive * 100
        # --- HI·ªÇN TH·ªä METRICS ---
        m1, m2, m3, m4, m5 = st.columns(5)
        m1.metric("T·ªïng chi ph√≠ (Reactive)", f"${total_reactive:,.2f}")
        m2.metric("T·ªïng chi ph√≠ (AI Model)", f"${total_ai:,.2f}", delta_color="inverse")
        
        delta_val = f"{savings:,.2f}"
        if savings > 0: delta_val = f"+{delta_val}"
        
        m3.metric("Ti·∫øt ki·ªám (Savings)", f"${savings:,.2f}", delta=delta_val)
        m4.metric("ROI (%)", f"{roi:.2f}%")
        m5.metric(
                    "SLA (%)",
                    f"{sla_ai_pct:.2f}%",
                    delta=f"{(sla_ai_pct - sla_reactive_pct):+.2f}%"
                )

        # --- BI·ªÇU ƒê·ªí ---
        st.markdown("#### üìâ So s√°nh Quy m√¥ Server")
        chart_data = df.melt(id_vars=["ds"], value_vars=["recommended_replicas", "reactive_replicas"], 
                             var_name="Chi·∫øn l∆∞·ª£c Scaling", value_name="Replicas")
        chart_data["Chi·∫øn l∆∞·ª£c Scaling"] = chart_data["Chi·∫øn l∆∞·ª£c Scaling"].map({
            "recommended_replicas": "AI D·ª± b√°o (Predictive)",
            "reactive_replicas": "Truy·ªÅn th·ªëng (Reactive)"
        })

        c = alt.Chart(chart_data).mark_line(interpolate='step-after').encode(
            x=alt.X('ds:T', title='Th·ªùi gian', axis=alt.Axis(format='%H:%M')),
            y=alt.Y('Replicas:Q', title='S·ªë l∆∞·ª£ng Server'),
            color=alt.Color('Chi·∫øn l∆∞·ª£c Scaling', scale=alt.Scale(range=['#00CC96', '#FF4B4B'])),
            tooltip=[
                alt.Tooltip('ds:T', title='Th·ªùi gian', format='%H:%M'),
                alt.Tooltip('Chi·∫øn l∆∞·ª£c Scaling'),
                alt.Tooltip('Replicas')
            ]
        ).interactive()
        st.altair_chart(c, use_container_width=True)

        # Bi·ªÉu ƒë·ªì r·ªõt request ƒë·ªÉ ch·ª©ng minh t·∫°i sao Reactive ph·∫°t n·∫∑ng
        total_dropped_reactive = df["dropped_reactive"].sum()
        total_dropped_ai = df["dropped_ai"].sum()

        if total_dropped_reactive > 0 or total_dropped_ai > 0:
            st.markdown("#### üìâ Ph√¢n t√≠ch Request b·ªã r·ªõt (Nguy√™n nh√¢n m·∫•t ti·ªÅn SLA)")
            st.caption(f"Bi·ªÉu ƒë·ªì d∆∞·ªõi ƒë√¢y so s√°nh l∆∞·ª£ng request b·ªã r·ªõt gi·ªØa hai chi·∫øn l∆∞·ª£c. "
                       f"Reactive th∆∞·ªùng b·ªã r·ªõt do ƒë·ªô tr·ªÖ khi scale up, d·∫´n ƒë·∫øn ph·∫°t SLA cao. "
                       f"(Reactive: {int(total_dropped_reactive):,} vs AI: {int(total_dropped_ai):,})")
            
            drop_data = df.melt(
                id_vars=["ds"], 
                value_vars=["dropped_reactive", "dropped_ai"], 
                var_name="Strategy", 
                value_name="Dropped"
            )
            
            drop_data["Strategy"] = drop_data["Strategy"].map({
                "dropped_reactive": "Reactive (Truy·ªÅn th·ªëng)",
                "dropped_ai": "AI Model (Predictive)"
            })

            c_drop = alt.Chart(drop_data).mark_area(opacity=0.6).encode(
                x=alt.X('ds:T', title='Th·ªùi gian', axis=alt.Axis(format='%H:%M')),
                y=alt.Y('Dropped:Q', title="S·ªë l∆∞·ª£ng Request b·ªã r·ªõt"),
                color=alt.Color('Strategy', scale=alt.Scale(domain=['Reactive (Truy·ªÅn th·ªëng)', 'AI Model (Predictive)'], range=['#FF4B4B', '#00CC96'])),
                tooltip=[
                    alt.Tooltip('ds:T', format='%H:%M'),
                    alt.Tooltip('Strategy', title='Chi·∫øn l∆∞·ª£c'),
                    alt.Tooltip('Dropped:Q', format=',.0f', title='Request r·ªõt')
                ]
            ).properties(height=250).interactive()
            
            st.altair_chart(c_drop, use_container_width=True)